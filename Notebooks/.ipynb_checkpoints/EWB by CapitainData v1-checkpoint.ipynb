{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "678fd01a",
   "metadata": {},
   "source": [
    "<h1> <center> Economic Well Being Prediction for African Countries</center> </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e212f7f",
   "metadata": {},
   "source": [
    "![Econmic Well Being Prediction for African Countries](http://governanceinnovation.org/wordpress/wp-content/uploads/2017/02/WE-Africa-LabsA4.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebf2c8a",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3807112",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T12:28:33.242571Z",
     "start_time": "2021-08-03T12:28:29.034811Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import statistics\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "\n",
    "import scripts.gaussianize as g \n",
    "\n",
    "import os \n",
    "import sys \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import RobustScaler, PowerTransformer, QuantileTransformer, FunctionTransformer, MinMaxScaler, StandardScaler, MaxAbsScaler\n",
    "from kaggler.preprocessing import FrequencyEncoder\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ed185f",
   "metadata": {},
   "source": [
    "## Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac48bd86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T12:28:33.292139Z",
     "start_time": "2021-08-03T12:28:33.245191Z"
    }
   },
   "outputs": [],
   "source": [
    "def metric(x, y):\n",
    "    return np.sqrt(mean_squared_error(x, y))\n",
    "\n",
    "skf = KFold(n_splits = 5,shuffle=True,random_state=199)\n",
    "\n",
    "def xgb_predict(estimator,train,label,test,estimator_name):\n",
    "    mean_train = []\n",
    "    mean_test_val = []\n",
    "    test_pred = np.zeros(test.shape[0])\n",
    "    val_pred = np.zeros(train.shape[0])\n",
    "    for count, (train_index,test_index) in enumerate(skf.split(train,label)):\n",
    "        x_train,x_test = train.iloc[train_index],train.iloc[test_index]\n",
    "        y_train,y_test = label.iloc[train_index],label.iloc[test_index]\n",
    "        print(f'========================Fold{count +1}==========================')\n",
    "        estimator.fit(x_train, y_train, early_stopping_rounds = 200, eval_metric=\"rmse\",\n",
    "                           eval_set=[(x_test, y_test)],verbose=2500)\n",
    "        train_predict = estimator.predict(x_train, ntree_limit = estimator.get_booster().best_ntree_limit)\n",
    "        test_predict = estimator.predict(x_test, ntree_limit = estimator.get_booster().best_ntree_limit)\n",
    "        val_pred[test_index] = test_predict\n",
    "        test_pred+= estimator.predict(test, ntree_limit = estimator.get_booster().best_ntree_limit)\n",
    "        \n",
    "        print('\\nTesting scores', metric(y_test,test_predict))\n",
    "        print('\\nTraining scores', metric(y_train,train_predict))\n",
    "        mean_train.append(metric(y_train, train_predict))\n",
    "        mean_test_val.append(metric(y_test,test_predict))\n",
    "    print('Average Testing ROC score for 5 folds split:',np.mean(mean_test_val))\n",
    "    print('Average Training ROC score for 5 folds split:',np.mean(mean_train))\n",
    "    print('standard Deviation for 5 folds split:',np.std(mean_test_val))\n",
    "    return val_pred, test_pred, estimator_name\n",
    "\n",
    "\n",
    "def cat_predict(estimator,train,label,test,estimator_name):\n",
    "    mean_train = []\n",
    "    mean_test_val = []\n",
    "    test_pred = np.zeros(test.shape[0])\n",
    "    val_pred = np.zeros(train.shape[0])\n",
    "    for count, (train_index,test_index) in enumerate(skf.split(train,label)):\n",
    "        x_train,x_test = train.iloc[train_index],train.iloc[test_index]\n",
    "        y_train,y_test = label.iloc[train_index],label.iloc[test_index]\n",
    "        x_train = np.nan_to_num(x_train)\n",
    "        y_train = np.nan_to_num(y_train)\n",
    "        x_test = np.nan_to_num(x_test)\n",
    "        y_test = np.nan_to_num(y_test)\n",
    "        \n",
    "        print(f'========================Fold{count +1}==========================')\n",
    "        estimator.fit(x_train,y_train,eval_set=[(x_test,y_test)],early_stopping_rounds=200,\n",
    "                           verbose=2500,use_best_model=True)\n",
    "        train_predict = estimator.predict(x_train)\n",
    "        test_predict = estimator.predict(x_test)\n",
    "        val_pred[test_index] = test_predict\n",
    "        test_pred+= estimator.predict(test)\n",
    "        \n",
    "        print('\\nTesting scores', metric(y_test,test_predict))\n",
    "        print('\\nTraining scores', metric(y_train,train_predict))\n",
    "        mean_train.append(metric(y_train, train_predict))\n",
    "        mean_test_val.append(metric(y_test,test_predict))\n",
    "    print('Average Testing ROC score for 5 folds split:',np.mean(mean_test_val))\n",
    "    print('Average Training ROC score for 5 folds split:',np.mean(mean_train))\n",
    "    print('standard Deviation for 5 folds split:',np.std(mean_test_val))\n",
    "    return val_pred, test_pred, estimator_name\n",
    "\n",
    "\n",
    "def lgb_predict(estimator,train,label,test,estimator_name):\n",
    "    mean_train = []\n",
    "    mean_test_val = []\n",
    "    test_pred = np.zeros(test.shape[0])\n",
    "    val_pred = np.zeros(train.shape[0])\n",
    "    for count, (train_index,test_index) in enumerate(skf.split(train,label)):\n",
    "        x_train,x_test = train.iloc[train_index].values,train.iloc[test_index].values\n",
    "        y_train,y_test = label.iloc[train_index].values,label.iloc[test_index].values\n",
    "        print(f'========================Fold{count +1}==========================')\n",
    "        estimator.fit(x_train,y_train,eval_set=[(x_test,y_test)],early_stopping_rounds=200,\n",
    "                               verbose=2500)\n",
    "        train_predict = estimator.predict(x_train, num_iteration = estimator.best_iteration_)\n",
    "        test_predict = estimator.predict(x_test, num_iteration = estimator.best_iteration_)\n",
    "        val_pred[test_index] = test_predict\n",
    "        test_pred+= estimator.predict(test, num_iteration = estimator.best_iteration_)\n",
    "        \n",
    "        print('\\nValidation scores', metric(y_test,test_predict))\n",
    "        print('\\nTraining scores', metric(y_train,train_predict))\n",
    "        mean_train.append(metric(y_train, train_predict))\n",
    "        mean_test_val.append(metric(y_test,test_predict))\n",
    "    print('Average Testing ROC score for 5 folds split:',np.mean(mean_test_val))\n",
    "    print('Average Training ROC score for 5 folds split:',np.mean(mean_train))\n",
    "    print('standard Deviation for 5 folds split:',np.std(mean_test_val))\n",
    "    return val_pred, test_pred, estimator_name\n",
    "\n",
    "def model_predict(estimator,train,label,test, estimator_name):\n",
    "    mean_train = []\n",
    "    mean_test_val = []\n",
    "    test_pred = np.zeros((test.shape[0]))\n",
    "    val_pred = np.zeros((train.shape[0]))\n",
    "    for count, (train_index,test_index) in enumerate(skf.split(train,label)):\n",
    "        x_train,x_test = train.iloc[train_index].values,train.iloc[test_index].values\n",
    "        y_train,y_test = label.iloc[train_index].values,label.iloc[test_index].values\n",
    "        print(f'========================Fold{count +1}==========================')\n",
    "        estimator.fit(x_train, y_train)\n",
    "        train_predict = estimator.predict(x_train)\n",
    "        test_predict = estimator.predict(x_test)\n",
    "        val_pred[test_index] = test_predict.reshape((test_predict.shape[0],))\n",
    "        test_pred+= estimator.predict(test.values)\n",
    "        \n",
    "        print('\\nValidation scores', metric(y_test,test_predict))\n",
    "        print('\\nTraining scores', metric(y_train,train_predict))\n",
    "        mean_train.append(metric(y_train, train_predict))\n",
    "        mean_test_val.append(metric(y_test,test_predict))\n",
    "    print('Average Testing RMSE  for 5 folds split:',np.mean(mean_test_val))\n",
    "    print('Average Training RMSE  for 5 folds split:',np.mean(mean_train))\n",
    "    print('standard Deviation for 5 folds split:',np.std(mean_test_val))\n",
    "    return val_pred, test_pred, estimator_name, np.mean(mean_test_val), np.mean(mean_train)\n",
    "\n",
    "def Create_StackDataFrames(train_preds, test_preds, names):\n",
    "    Train_stack = pd.concat([pd.Series(tr_pred, name=name) for tr_pred, name in zip(train_preds, names)],1)\n",
    "    \n",
    "    Test_stack = pd.concat([pd.Series(te_pred, name=name) for te_pred, name in zip(test_preds, names)],1)\n",
    "    \n",
    "    Test_stack = Test_stack/5 #average predictions for 5 folds on the Test set..\n",
    "    \n",
    "    return Train_stack, Test_stack\n",
    "    \n",
    "def Stack(meta_estimator,Train_stack,Test_stack,target,file_name):\n",
    "    \n",
    "    val_pred, test_pred, estimator_name, test_score, train_score = model_predict(meta_estimator,Train_stack, ytrain, Test_stack, \"Ridge\")\n",
    "    \n",
    "    prediction = test_pred/5#meta_estimator.fit(Train_stack, target).predict(Test_stack)\n",
    "    ss['Target'] = prediction#np.round(np.absolute(prediction), 0)\n",
    "    \n",
    "    ss.Target=ss.Target.apply(abs)\n",
    "    \n",
    "    ss.to_csv(file_name,index=False)\n",
    "#     ss.describe()\n",
    "    return ss, val_pred, test_pred, estimator_name, test_score, train_score\n",
    "\n",
    "def trainer(model_name, xtrain, ytrain, xtest):\n",
    "    catboost =  CatBoostRegressor(random_seed=34,use_best_model=True,\n",
    "                          n_estimators=400000,silent=True,eval_metric='RMSE')\n",
    "\n",
    "    cat1_train, cat1_test, cat1_name = cat_predict(catboost,xtrain, ytrain, xtest,  'catboost(1)')\n",
    "    \n",
    "    lgb_model = LGBMRegressor(random_state=34, n_estimators=100000, colsample_bytree=0.9, min_child_samples=10, subsample=0.7,subsample_freq=2,num_leaves=120,reg_lambda=1,reg_alpha=1, metric=\"rmse\", learning_rate=0.01, max_depth=5\n",
    "                             )\n",
    "\n",
    "    LGB1__train, LGB1_test, LGB1_name =lgb_predict(lgb_model,xtrain, ytrain, xtest,'lightgbm(1)')\n",
    "    \n",
    "    Train_stack1, Test_stack1 = Create_StackDataFrames([cat1_train, LGB1__train], [cat1_test, LGB1_test], [cat1_name, LGB1_name])\n",
    "    \n",
    "    \n",
    "    meta_estimator = Ridge()\n",
    "    \n",
    "    ss, val_pred, test_pred, estimator_name, test_score, train_score = Stack(meta_estimator, Train_stack1, Test_stack1, ytrain, f'../Submissions/stack_{model_name}.csv') \n",
    "\n",
    "    return ss, val_pred, test_pred, estimator_name, test_score, train_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49098113",
   "metadata": {},
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdaded0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T12:28:33.392572Z",
     "start_time": "2021-08-03T12:28:33.294921Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SampleSubmission.csv', 'Test.csv', 'Train.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(os.listdir(\"../Data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb877631",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T12:28:33.575691Z",
     "start_time": "2021-08-03T12:28:33.395221Z"
    }
   },
   "outputs": [],
   "source": [
    "ss, test, train= [pd.read_csv(f\"../Data/{f}\") for f in sorted(os.listdir(\"../Data/\")) if f.endswith(\".csv\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb3687d",
   "metadata": {},
   "source": [
    "## Preprocessing Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042fd69b",
   "metadata": {},
   "source": [
    "**Normalization techniques**:\n",
    "    \n",
    "    * The Lambert W x F transformation\n",
    "    * The Box Cox tranformation\n",
    "    * The Yeo-Johnson transformation\n",
    "    * The Ordered Quantile technique\n",
    "    * The Logarithm of base `b` and default value `a` log_{b}(x+a)\n",
    "    * The sqrt transformation\n",
    "    * The Exponential transformation \n",
    "    * The arcsinus hyperbolic transformation \n",
    "    * Modified Box Cox (1964)\n",
    "    * Manly’s Exponential (1976)\n",
    "    * John/Draper’s Modulus (1980), \n",
    "    * Bickel/Doksum’s Modified Box Cox (1981)\n",
    "    * Min-Max Normalization\n",
    "    * Z-Score Standardization\n",
    "    * Median-Max Normalization (CapitainData)\n",
    "    * Feature Clipping\n",
    "    * Quantile Normalization\n",
    "    * Reciprocal Transformation \n",
    "    * Power Transformation \n",
    "   + Normalization by Categorical variables (country, year, or urban_or_rural)\n",
    "    \n",
    " - Selecting the best technique\n",
    "\n",
    " **Encoding Techniques**:\n",
    " \n",
    "    + Supervised:\n",
    "    \n",
    "        ° Target Encoding (Mean, var, min, max, std, ...)\n",
    "        \n",
    "        ° Bayesian Target Encoding / Conjugate Prior Encoding\n",
    "        \n",
    "        ° CatBoost \n",
    "        \n",
    "        ° Generalized Linear Mixed Model \n",
    "        \n",
    "        ° James-Stein Estimator \n",
    "        \n",
    "        ° LeaveOneOut \n",
    "        \n",
    "        ° M-estimator \n",
    "        \n",
    "        ° Weight of Evidence\n",
    "        \n",
    "        ° Hierarchical Bayesian Target Encoding\n",
    "        \n",
    "        ° Probability Ratio\n",
    "        \n",
    "        ° DecisionTree Encoder\n",
    "        \n",
    "        ° RareLabel Encoder\n",
    "        \n",
    "        ° Target guided Ordinal Encoding\n",
    "        \n",
    "    + Unsupervised:\n",
    "\n",
    "        ° Backward Difference Contrast \n",
    "        \n",
    "        ° BaseN \n",
    "        \n",
    "        ° Binary \n",
    "        \n",
    "        ° Count \n",
    "        \n",
    "        ° Hashing \n",
    "        \n",
    "        ° Helmert Contrast \n",
    "        \n",
    "        ° Ordinal \n",
    "        \n",
    "        ° One-Hot \n",
    "        \n",
    "        ° Label\n",
    "        \n",
    "        ° Polynomial Contrast \n",
    "        \n",
    "        ° Sum Contrast \n",
    "        \n",
    "        ° Thermometer Encoder \n",
    "\n",
    "\n",
    "**Discretisation techniques**:\n",
    "\n",
    "        & Equal Frequency Discretiser\n",
    "        & EqualWidthDiscretiser\n",
    "        & ArbitraryDiscretiser \n",
    "        & DecisionTreeDiscretiser\n",
    "        \n",
    "\n",
    "\n",
    "**Feature Creation techniques**:\n",
    "\n",
    "        @ MathematicalCombination\n",
    "        @ CombineWithReferenceFeature\n",
    "        @ CyclicalTransformer\n",
    "\n",
    "**Feature Selection techniques**:\n",
    "\n",
    "        p Drop Freatures\n",
    "        p Drop Constant Features \n",
    "        p Drop Duplicate Features \n",
    "        p Drop Correlated Features \n",
    "        p Smart Correlated Features \n",
    "        p Select By Shuffling\n",
    "        p Select By Single Feature Performance\n",
    "        p Select By Target Mean Performance\n",
    "        p Recursive Feature Elimination\n",
    "        p Recursive Feature Addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cf58cc5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T12:28:33.589283Z",
     "start_time": "2021-08-03T12:28:33.579421Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocessor(train, test, normalizer=RobustScaler(), encoder=FrequencyEncoder()):\n",
    "    print(\"\\n Procesing started \\n\")\n",
    "    to_scale =[\"ghsl_pop_density\", \"nighttime_lights\", \"dist_to_shoreline\", \"dist_to_capital\"]\n",
    "    \n",
    "    to_scale_100 = [\"landcover_crops_fraction\", \"landcover_urban_fraction\", \"landcover_water_permanent_10km_fraction\", \"landcover_water_seasonal_10km_fraction\"]\n",
    "    \n",
    "    train[to_scale_100]=train[to_scale_100]/100\n",
    "    test[to_scale_100]=test[to_scale_100]/100\n",
    "    \n",
    "#     scaler=RobustScaler()#MinMaxScaler()\n",
    "    normalizer.fit(train[to_scale].apply(lambda x: x+8))\n",
    "    train[to_scale]=normalizer.transform(train[to_scale].apply(lambda x: x+8))\n",
    "    test[to_scale]=normalizer.transform(test[to_scale].apply(lambda x: x+8))\n",
    "    \n",
    "    ntrain=train.shape[0]\n",
    "    train_ids=train.ID.unique()\n",
    "    test_ids=test.ID.unique() \n",
    "    all_data=pd.concat([train, test], axis=0)\n",
    "    \n",
    "    cat_cols = [\"country\", \"urban_or_rural\", \"year\"]\n",
    "    float_cols = train.columns.difference(cat_cols+[\"Target\", \"ID\"])\n",
    "    \n",
    "    all_data.year=all_data.year.apply(str)\n",
    "    \n",
    "#     fe = FrequencyEncoder() \n",
    "    \n",
    "    all_data[cat_cols]=encoder.fit_transform(all_data[cat_cols])\n",
    "    \n",
    "    train = all_data.loc[all_data.ID.isin(train_ids)]#all_data[:ntrain]\n",
    "    test = all_data.loc[all_data.ID.isin(test_ids)]#all_data[ntrain:]\n",
    "    \n",
    "    main_cols=train.columns.difference([\"ID\", 'Target'])\n",
    "    xtrain = train[main_cols]\n",
    "    xtest = test[main_cols]\n",
    "    ytrain=train.Target \n",
    "    \n",
    "    print(\"Processing completed \\n\")\n",
    "    return xtrain, ytrain, xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8af3bd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T12:54:46.833659Z",
     "start_time": "2021-08-03T12:28:33.591397Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Procesing started \n",
      "\n",
      "Processing completed \n",
      "\n",
      "========================Fold1==========================\n",
      "Learning rate set to 0.001887\n",
      "0:\tlearn: 0.1943936\ttest: 0.1931049\tbest: 0.1931049 (0)\ttotal: 55.2ms\tremaining: 6h 7m 40s\n",
      "2500:\tlearn: 0.0932023\ttest: 0.0935957\tbest: 0.0935957 (2500)\ttotal: 14.9s\tremaining: 39m 31s\n",
      "5000:\tlearn: 0.0878585\ttest: 0.0895007\tbest: 0.0895007 (5000)\ttotal: 28.2s\tremaining: 37m 6s\n",
      "7500:\tlearn: 0.0846477\ttest: 0.0878726\tbest: 0.0878726 (7500)\ttotal: 40.9s\tremaining: 35m 39s\n",
      "10000:\tlearn: 0.0823027\ttest: 0.0870770\tbest: 0.0870770 (10000)\ttotal: 53.6s\tremaining: 34m 48s\n",
      "12500:\tlearn: 0.0804954\ttest: 0.0866034\tbest: 0.0866034 (12500)\ttotal: 1m 6s\tremaining: 34m 6s\n",
      "15000:\tlearn: 0.0789069\ttest: 0.0862715\tbest: 0.0862715 (15000)\ttotal: 1m 19s\tremaining: 33m 57s\n",
      "17500:\tlearn: 0.0774551\ttest: 0.0860134\tbest: 0.0860134 (17500)\ttotal: 1m 50s\tremaining: 40m 23s\n",
      "20000:\tlearn: 0.0761520\ttest: 0.0858325\tbest: 0.0858321 (19998)\ttotal: 2m 3s\tremaining: 39m 7s\n",
      "22500:\tlearn: 0.0749450\ttest: 0.0857047\tbest: 0.0857047 (22500)\ttotal: 2m 32s\tremaining: 42m 30s\n",
      "25000:\tlearn: 0.0738397\ttest: 0.0856310\tbest: 0.0856308 (24991)\ttotal: 2m 44s\tremaining: 41m 10s\n",
      "27500:\tlearn: 0.0727959\ttest: 0.0855776\tbest: 0.0855770 (27465)\ttotal: 2m 58s\tremaining: 40m 22s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.08556826547\n",
      "bestIteration = 28341\n",
      "\n",
      "Shrink model to first 28342 iterations.\n",
      "\n",
      "Testing scores 0.08556826532376365\n",
      "\n",
      "Training scores 0.07246083403740332\n",
      "========================Fold2==========================\n",
      "Learning rate set to 0.001887\n",
      "0:\tlearn: 0.1936635\ttest: 0.1960254\tbest: 0.1960254 (0)\ttotal: 6.85ms\tremaining: 45m 39s\n",
      "2500:\tlearn: 0.0928946\ttest: 0.0950519\tbest: 0.0950519 (2500)\ttotal: 14.2s\tremaining: 37m 37s\n",
      "5000:\tlearn: 0.0875149\ttest: 0.0908688\tbest: 0.0908688 (5000)\ttotal: 45.6s\tremaining: 1h\n",
      "7500:\tlearn: 0.0842485\ttest: 0.0892238\tbest: 0.0892238 (7500)\ttotal: 1m\tremaining: 52m 20s\n",
      "10000:\tlearn: 0.0818877\ttest: 0.0884545\tbest: 0.0884545 (10000)\ttotal: 1m 28s\tremaining: 57m 44s\n",
      "12500:\tlearn: 0.0800236\ttest: 0.0880101\tbest: 0.0880101 (12500)\ttotal: 1m 42s\tremaining: 52m 48s\n",
      "15000:\tlearn: 0.0784334\ttest: 0.0877037\tbest: 0.0877037 (15000)\ttotal: 1m 54s\tremaining: 49m 5s\n",
      "17500:\tlearn: 0.0769901\ttest: 0.0874482\tbest: 0.0874482 (17499)\ttotal: 2m 24s\tremaining: 52m 44s\n",
      "20000:\tlearn: 0.0756865\ttest: 0.0872597\tbest: 0.0872596 (19999)\ttotal: 2m 38s\tremaining: 50m 19s\n",
      "22500:\tlearn: 0.0744839\ttest: 0.0870997\tbest: 0.0870997 (22500)\ttotal: 3m 10s\tremaining: 53m 17s\n",
      "25000:\tlearn: 0.0733688\ttest: 0.0870047\tbest: 0.0870044 (24999)\ttotal: 3m 28s\tremaining: 52m 7s\n",
      "27500:\tlearn: 0.0723417\ttest: 0.0869378\tbest: 0.0869374 (27486)\ttotal: 3m 58s\tremaining: 53m 52s\n",
      "30000:\tlearn: 0.0713774\ttest: 0.0868720\tbest: 0.0868719 (29998)\ttotal: 4m 25s\tremaining: 54m 37s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.08686873878\n",
      "bestIteration = 30242\n",
      "\n",
      "Shrink model to first 30243 iterations.\n",
      "\n",
      "Testing scores 0.08686873849685081\n",
      "\n",
      "Training scores 0.07128418176496672\n",
      "========================Fold3==========================\n",
      "Learning rate set to 0.001887\n",
      "0:\tlearn: 0.1943164\ttest: 0.1934262\tbest: 0.1934262 (0)\ttotal: 6.41ms\tremaining: 42m 45s\n",
      "2500:\tlearn: 0.0926242\ttest: 0.0964815\tbest: 0.0964815 (2500)\ttotal: 13.4s\tremaining: 35m 33s\n",
      "5000:\tlearn: 0.0872907\ttest: 0.0920216\tbest: 0.0920216 (5000)\ttotal: 46.8s\tremaining: 1h 1m 38s\n",
      "7500:\tlearn: 0.0841306\ttest: 0.0901259\tbest: 0.0901257 (7498)\ttotal: 1m\tremaining: 52m 55s\n",
      "10000:\tlearn: 0.0818727\ttest: 0.0893177\tbest: 0.0893173 (9998)\ttotal: 1m 32s\tremaining: 1h 5s\n",
      "12500:\tlearn: 0.0799845\ttest: 0.0887711\tbest: 0.0887711 (12500)\ttotal: 1m 45s\tremaining: 54m 27s\n",
      "15000:\tlearn: 0.0783180\ttest: 0.0883708\tbest: 0.0883707 (14997)\ttotal: 2m 17s\tremaining: 58m 48s\n",
      "17500:\tlearn: 0.0768682\ttest: 0.0880799\tbest: 0.0880799 (17500)\ttotal: 2m 31s\tremaining: 55m\n",
      "20000:\tlearn: 0.0756103\ttest: 0.0878703\tbest: 0.0878703 (20000)\ttotal: 3m 4s\tremaining: 58m 25s\n",
      "22500:\tlearn: 0.0744385\ttest: 0.0876973\tbest: 0.0876973 (22500)\ttotal: 3m 18s\tremaining: 55m 29s\n",
      "25000:\tlearn: 0.0733375\ttest: 0.0875814\tbest: 0.0875811 (24997)\ttotal: 3m 58s\tremaining: 59m 32s\n",
      "27500:\tlearn: 0.0722925\ttest: 0.0874739\tbest: 0.0874734 (27489)\ttotal: 4m 31s\tremaining: 1h 1m 19s\n",
      "30000:\tlearn: 0.0713012\ttest: 0.0873843\tbest: 0.0873840 (29992)\ttotal: 4m 45s\tremaining: 58m 45s\n",
      "32500:\tlearn: 0.0703567\ttest: 0.0873067\tbest: 0.0873066 (32499)\ttotal: 5m 16s\tremaining: 59m 33s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.08724613211\n",
      "bestIteration = 34757\n",
      "\n",
      "Shrink model to first 34758 iterations.\n",
      "\n",
      "Testing scores 0.08724613220144598\n",
      "\n",
      "Training scores 0.06955424421006604\n",
      "========================Fold4==========================\n",
      "Learning rate set to 0.001887\n",
      "0:\tlearn: 0.1942477\ttest: 0.1937013\tbest: 0.1937013 (0)\ttotal: 5.37ms\tremaining: 35m 49s\n",
      "2500:\tlearn: 0.0930423\ttest: 0.0946113\tbest: 0.0946113 (2500)\ttotal: 27.7s\tremaining: 1h 13m 29s\n",
      "5000:\tlearn: 0.0877469\ttest: 0.0904472\tbest: 0.0904472 (5000)\ttotal: 39.6s\tremaining: 52m 7s\n",
      "7500:\tlearn: 0.0845213\ttest: 0.0884484\tbest: 0.0884484 (7500)\ttotal: 52.8s\tremaining: 46m 3s\n",
      "10000:\tlearn: 0.0821613\ttest: 0.0875170\tbest: 0.0875170 (10000)\ttotal: 1m 20s\tremaining: 52m 36s\n",
      "12500:\tlearn: 0.0802844\ttest: 0.0869900\tbest: 0.0869900 (12500)\ttotal: 1m 33s\tremaining: 48m 30s\n",
      "15000:\tlearn: 0.0786903\ttest: 0.0866614\tbest: 0.0866614 (15000)\ttotal: 2m 6s\tremaining: 53m 56s\n",
      "17500:\tlearn: 0.0772718\ttest: 0.0864341\tbest: 0.0864341 (17500)\ttotal: 2m 20s\tremaining: 51m 5s\n",
      "20000:\tlearn: 0.0759623\ttest: 0.0862334\tbest: 0.0862331 (19994)\ttotal: 2m 52s\tremaining: 54m 41s\n",
      "22500:\tlearn: 0.0747643\ttest: 0.0860621\tbest: 0.0860621 (22500)\ttotal: 3m 17s\tremaining: 55m 7s\n",
      "25000:\tlearn: 0.0736970\ttest: 0.0859382\tbest: 0.0859382 (25000)\ttotal: 3m 38s\tremaining: 54m 38s\n",
      "27500:\tlearn: 0.0726892\ttest: 0.0858338\tbest: 0.0858337 (27498)\ttotal: 3m 52s\tremaining: 52m 25s\n",
      "30000:\tlearn: 0.0717177\ttest: 0.0857526\tbest: 0.0857524 (29989)\ttotal: 4m 23s\tremaining: 54m 11s\n",
      "32500:\tlearn: 0.0707876\ttest: 0.0856821\tbest: 0.0856819 (32499)\ttotal: 4m 55s\tremaining: 55m 46s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.08563652882\n",
      "bestIteration = 34603\n",
      "\n",
      "Shrink model to first 34604 iterations.\n",
      "\n",
      "Testing scores 0.0856365289530974\n",
      "\n",
      "Training scores 0.07002635494852155\n",
      "========================Fold5==========================\n",
      "Learning rate set to 0.001887\n",
      "0:\tlearn: 0.1940559\ttest: 0.1944395\tbest: 0.1944395 (0)\ttotal: 6.16ms\tremaining: 41m 4s\n",
      "2500:\tlearn: 0.0937222\ttest: 0.0922784\tbest: 0.0922784 (2500)\ttotal: 29.8s\tremaining: 1h 19m 4s\n",
      "5000:\tlearn: 0.0884954\ttest: 0.0876162\tbest: 0.0876162 (5000)\ttotal: 44.8s\tremaining: 58m 56s\n",
      "7500:\tlearn: 0.0854080\ttest: 0.0857040\tbest: 0.0857040 (7500)\ttotal: 1m 17s\tremaining: 1h 8m\n",
      "10000:\tlearn: 0.0831600\ttest: 0.0847203\tbest: 0.0847203 (10000)\ttotal: 1m 30s\tremaining: 59m 4s\n",
      "12500:\tlearn: 0.0812713\ttest: 0.0840982\tbest: 0.0840980 (12499)\ttotal: 2m 2s\tremaining: 1h 3m 15s\n",
      "15000:\tlearn: 0.0796457\ttest: 0.0836824\tbest: 0.0836822 (14998)\ttotal: 2m 14s\tremaining: 57m 27s\n",
      "17500:\tlearn: 0.0782171\ttest: 0.0833695\tbest: 0.0833695 (17500)\ttotal: 2m 43s\tremaining: 59m 36s\n",
      "20000:\tlearn: 0.0769376\ttest: 0.0831264\tbest: 0.0831264 (20000)\ttotal: 2m 57s\tremaining: 56m 12s\n",
      "22500:\tlearn: 0.0757857\ttest: 0.0829585\tbest: 0.0829585 (22500)\ttotal: 3m 20s\tremaining: 56m 5s\n",
      "25000:\tlearn: 0.0747065\ttest: 0.0828380\tbest: 0.0828380 (25000)\ttotal: 3m 41s\tremaining: 55m 21s\n",
      "27500:\tlearn: 0.0736943\ttest: 0.0827424\tbest: 0.0827424 (27500)\ttotal: 4m 2s\tremaining: 54m 49s\n",
      "30000:\tlearn: 0.0727311\ttest: 0.0826663\tbest: 0.0826659 (29963)\ttotal: 4m 21s\tremaining: 53m 50s\n",
      "32500:\tlearn: 0.0718037\ttest: 0.0826052\tbest: 0.0826052 (32500)\ttotal: 4m 34s\tremaining: 51m 42s\n",
      "35000:\tlearn: 0.0709038\ttest: 0.0825523\tbest: 0.0825517 (34981)\ttotal: 5m 2s\tremaining: 52m 37s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.0825442246\n",
      "bestIteration = 35349\n",
      "\n",
      "Shrink model to first 35350 iterations.\n",
      "\n",
      "Testing scores 0.0825442243907082\n",
      "\n",
      "Training scores 0.07078404770361253\n",
      "Average Testing ROC score for 5 folds split: 0.08557277787317319\n",
      "Average Training ROC score for 5 folds split: 0.07082193253291404\n",
      "standard Deviation for 5 folds split: 0.0016526251483937088\n",
      "========================Fold1==========================\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2500]\tvalid_0's rmse: 0.0863529\n",
      "Early stopping, best iteration is:\n",
      "[3475]\tvalid_0's rmse: 0.0862236\n",
      "\n",
      "Validation scores 0.08622363499451881\n",
      "\n",
      "Training scores 0.07172311045613941\n",
      "========================Fold2==========================\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[2500]\tvalid_0's rmse: 0.0868272\n",
      "Early stopping, best iteration is:\n",
      "[4136]\tvalid_0's rmse: 0.0865136\n",
      "\n",
      "Validation scores 0.08651356009028356\n",
      "\n",
      "Training scores 0.07018485693458079\n",
      "========================Fold3==========================\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[2500]\tvalid_0's rmse: 0.0874155\n",
      "[5000]\tvalid_0's rmse: 0.0868777\n",
      "Early stopping, best iteration is:\n",
      "[5314]\tvalid_0's rmse: 0.08685\n",
      "\n",
      "Validation scores 0.08685004029931383\n",
      "\n",
      "Training scores 0.06766671840777502\n",
      "========================Fold4==========================\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[2500]\tvalid_0's rmse: 0.0858238\n",
      "Early stopping, best iteration is:\n",
      "[4062]\tvalid_0's rmse: 0.0854992\n",
      "\n",
      "Validation scores 0.08549918845916478\n",
      "\n",
      "Training scores 0.0705489904226157\n",
      "========================Fold5==========================\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[2500]\tvalid_0's rmse: 0.0828292\n",
      "Early stopping, best iteration is:\n",
      "[3810]\tvalid_0's rmse: 0.0825494\n",
      "\n",
      "Validation scores 0.08254939829474094\n",
      "\n",
      "Training scores 0.07172498428667794\n",
      "Average Testing ROC score for 5 folds split: 0.08552716442760439\n",
      "Average Training ROC score for 5 folds split: 0.07036973210155777\n",
      "standard Deviation for 5 folds split: 0.0015540863568489416\n",
      "========================Fold1==========================\n",
      "\n",
      "Validation scores 0.08563681552216548\n",
      "\n",
      "Training scores 0.08515935088842358\n",
      "========================Fold2==========================\n",
      "\n",
      "Validation scores 0.08639859360524069\n",
      "\n",
      "Training scores 0.08496843692372222\n",
      "========================Fold3==========================\n",
      "\n",
      "Validation scores 0.08670206187213966\n",
      "\n",
      "Training scores 0.08488827051127756\n",
      "========================Fold4==========================\n",
      "\n",
      "Validation scores 0.08535732892238537\n",
      "\n",
      "Training scores 0.08523186136649587\n",
      "========================Fold5==========================\n",
      "\n",
      "Validation scores 0.08224215308269325\n",
      "\n",
      "Training scores 0.0859950367592963\n",
      "Average Testing RMSE  for 5 folds split: 0.08526739060092488\n",
      "Average Training RMSE  for 5 folds split: 0.0852485912898431\n",
      "standard Deviation for 5 folds split: 0.0015896243335605526\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7194.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.327742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.175333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.080906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.182593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.262342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.477112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.772570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Target\n",
       "count  7194.000000\n",
       "mean      0.327742\n",
       "std       0.175333\n",
       "min       0.080906\n",
       "25%       0.182593\n",
       "50%       0.262342\n",
       "75%       0.477112\n",
       "max       0.772570"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain, ytrain, xtest = preprocessor(train, test)\n",
    "\n",
    "ss, val_pred, test_pred, estimator_name, test_score, train_score = trainer(\"baseline\", xtrain, ytrain, xtest)\n",
    "\n",
    "ss.describe()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
